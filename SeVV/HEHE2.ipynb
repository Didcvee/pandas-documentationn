{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from clickhouse_driver import Client\n",
    "import pandas as pd\n",
    "\n",
    "client = Client(host='localhost', database='metro')\n",
    "query = \"SELECT * FROM station\"\n",
    "data = client.execute(query)\n",
    "df = pd.DataFrame(data, columns=['C/A', 'Unit', 'SCP', 'Station', 'Date', 'Time', 'Description', 'Entries', 'Exits', 'datetime','turnstile'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Преобразование данных\n",
    "df['datetime'] = pd.to_datetime(df['Date'].astype(str) + ' ' + df['Time'])\n",
    "df['entries_diff'] = df.groupby('turnstile')['Entries'].diff().fillna(0)\n",
    "df['exits_diff'] = df.groupby('turnstile')['Exits'].diff().fillna(0)\n",
    "df['traffic'] = df['entries_diff'] + df['exits_diff']\n",
    "\n",
    "# Создание приложения Dash\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Анализ данных станции метро\"),\n",
    "    html.Label(\"Выберите станцию:\"),\n",
    "    dcc.Dropdown(\n",
    "        id='station-dropdown',\n",
    "        options=[{'label': station, 'value': station} for station in df['Station'].unique()],\n",
    "        value=df['Station'].unique()[0]\n",
    "    ),\n",
    "    html.Label(\"Выберите временной промежуток:\"),\n",
    "    dcc.DatePickerRange(\n",
    "        id='date-picker',\n",
    "        start_date=df['datetime'].min().date(),\n",
    "        end_date=df['datetime'].max().date()\n",
    "    ),\n",
    "    dcc.Graph(id='traffic-graph'),\n",
    "    dcc.Graph(id='capacity-graph'),\n",
    "    dcc.Graph(id='top-stations-graph'),\n",
    "    dcc.Graph(id='average-passengers-graph')\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    [Output('traffic-graph', 'figure'),\n",
    "     Output('capacity-graph', 'figure'),\n",
    "     Output('top-stations-graph', 'figure'),\n",
    "     Output('average-passengers-graph', 'figure')],\n",
    "    [Input('station-dropdown', 'value'),\n",
    "     Input('date-picker', 'start_date'),\n",
    "     Input('date-picker', 'end_date')]\n",
    ")\n",
    "def update_graphs(selected_station, start_date, end_date):\n",
    "    filtered_df = df[(df['Station'] == selected_station) & \n",
    "                     (df['datetime'] >= pd.to_datetime(start_date)) & \n",
    "                     (df['datetime'] <= pd.to_datetime(end_date))]\n",
    "\n",
    "    # 1. Загруженность станции\n",
    "    max_traffic = df['traffic'].max()\n",
    "    filtered_df['load_percent'] = (filtered_df['traffic'] / max_traffic) * 100\n",
    "    load_fig = px.line(filtered_df, x='datetime', y='load_percent', title='Загруженность станции (%)')\n",
    "\n",
    "    # 2. Пропускная способность\n",
    "    capacity_fig = px.line(filtered_df, x='datetime', y='traffic', title='Пропускная способность станции')\n",
    "\n",
    "    # 3. Топ загруженных станций\n",
    "    top_stations = df.groupby('Station')['traffic'].sum().reset_index()\n",
    "    top_stations = top_stations.sort_values(by='traffic', ascending=False).head(10)\n",
    "    top_stations_fig = px.bar(top_stations, x='Station', y='traffic', title='Топ загруженных станций')\n",
    "\n",
    "    # 4. Среднее количество пассажиров\n",
    "    avg_passengers = filtered_df['traffic'].mean()\n",
    "    avg_passengers_fig = px.line(filtered_df, x='datetime', y='traffic', title=f'Среднее количество пассажиров: {avg_passengers:.2f}')\n",
    "\n",
    "    return load_fig, capacity_fig, top_stations_fig, avg_passengers_fig\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb280fbb932d7822"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from clickhouse_driver import Client\n",
    "import pandas as pd\n",
    "\n",
    "client = Client(host='localhost', database='metro')\n",
    "query = \"SELECT * FROM station\"\n",
    "data = client.execute(query)\n",
    "df = pd.DataFrame(data, columns=['C/A', 'Unit', 'SCP', 'Station', 'Date', 'Time', 'Description', 'Entries', 'Exits', 'datetime','turnstile'])\n",
    "\n",
    "# Преобразование столбца datetime в тип данных datetime\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "# Извлечение дополнительных признаков из datetime\n",
    "df['hour'] = df['datetime'].dt.hour\n",
    "df['day_of_week'] = df['datetime'].dt.dayofweek\n",
    "\n",
    "# Вычисление количества входов и выходов за каждый интервал времени\n",
    "df['entry_diff'] = df.groupby('turnstile')['Entries'].diff().fillna(0)\n",
    "df['exit_diff'] = df.groupby('turnstile')['Exits'].diff().fillna(0)\n",
    "\n",
    "# Удаление строк с отрицательными значениями entry_diff и exit_diff\n",
    "df = df[(df['entry_diff'] >= 0) & (df['exit_diff'] >= 0)]\n",
    "\n",
    "# Проверка данных\n",
    "print(df.head())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b8f3ce88e134c83"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Подготовка данных для кластеризации\n",
    "features = df[['hour', 'day_of_week', 'entry_diff', 'exit_diff']]\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# K-Means\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans_labels = kmeans.fit_predict(scaled_features)\n",
    "\n",
    "# DBSCAN\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=10)\n",
    "dbscan_labels = dbscan.fit_predict(scaled_features)\n",
    "\n",
    "# Иерархическая кластеризация\n",
    "agg_clustering = AgglomerativeClustering(n_clusters=3)\n",
    "agg_labels = agg_clustering.fit_predict(scaled_features)\n",
    "\n",
    "# Добавление меток кластеров в данные\n",
    "df['kmeans_cluster'] = kmeans_labels\n",
    "df['dbscan_cluster'] = dbscan_labels\n",
    "df['agg_cluster'] = agg_labels\n",
    "\n",
    "# Оценка качества кластеризации\n",
    "kmeans_silhouette = silhouette_score(scaled_features, kmeans_labels)\n",
    "dbscan_silhouette = silhouette_score(scaled_features, dbscan_labels)\n",
    "agg_silhouette = silhouette_score(scaled_features, agg_labels)\n",
    "\n",
    "kmeans_db = davies_bouldin_score(scaled_features, kmeans_labels)\n",
    "dbscan_db = davies_bouldin_score(scaled_features, dbscan_labels)\n",
    "agg_db = davies_bouldin_score(scaled_features, agg_labels)\n",
    "\n",
    "# Печать результатов\n",
    "print(f\"K-Means Silhouette Score: {kmeans_silhouette}, Davies-Bouldin Score: {kmeans_db}\")\n",
    "print(f\"DBSCAN Silhouette Score: {dbscan_silhouette}, Davies-Bouldin Score: {dbscan_db}\")\n",
    "print(f\"Agglomerative Clustering Silhouette Score: {agg_silhouette}, Davies-Bouldin Score: {agg_db}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a007415bc6d07222"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Подготовка данных для кластеризации\n",
    "features = df[['hour', 'day_of_week', 'entry_diff', 'exit_diff']]\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19e747a333d2ad34"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# K-Means\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans_labels = kmeans.fit_predict(scaled_features)\n",
    "\n",
    "print(df.head())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee1b44b313dc4003"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# DBSCAN\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=10)\n",
    "dbscan_labels = dbscan.fit_predict(scaled_features)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab2f9f3df4c39202"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Иерархическая кластеризация\n",
    "agg_clustering = AgglomerativeClustering(n_clusters=3)\n",
    "agg_labels = agg_clustering.fit_predict(scaled_features)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "871e3b343cf5e120"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Добавление меток кластеров в данные\n",
    "df['kmeans_cluster'] = kmeans_labels\n",
    "# df['dbscan_cluster'] = dbscan_labels\n",
    "# df['agg_cluster'] = agg_labels\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "993bc1bb9d69e6f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Оценка качества кластеризации\n",
    "kmeans_silhouette = silhouette_score(scaled_features, kmeans_labels)\n",
    "# dbscan_silhouette = silhouette_score(scaled_features, dbscan_labels)\n",
    "# agg_silhouette = silhouette_score(scaled_features, agg_labels)\n",
    "\n",
    "kmeans_db = davies_bouldin_score(scaled_features, kmeans_labels)\n",
    "# dbscan_db = davies_bouldin_score(scaled_features, dbscan_labels)\n",
    "# agg_db = davies_bouldin_score(scaled_features, agg_labels)\n",
    "\n",
    "# Печать результатов\n",
    "print(f\"K-Means Silhouette Score: {kmeans_silhouette}, Davies-Bouldin Score: {kmeans_db}\")\n",
    "# print(f\"DBSCAN Silhouette Score: {dbscan_silhouette}, Davies-Bouldin Score: {dbscan_db}\")\n",
    "# print(f\"Agglomerative Clustering Silhouette Score: {agg_silhouette}, Davies-Bouldin Score: {agg_db}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cce993cfb37dcfa5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Визуализация кластеров K-Means\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(data=df, x='hour', y='entry_diff', hue='kmeans_cluster', palette='viridis')\n",
    "plt.title('K-Means Clustering')\n",
    "plt.show()\n",
    "\n",
    "# # Визуализация кластеров DBSCAN\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.scatterplot(data=data, x='hour', y='entry_diff', hue='dbscan_cluster', palette='viridis')\n",
    "# plt.title('DBSCAN Clustering')\n",
    "# plt.show()\n",
    "# \n",
    "# # Визуализация кластеров иерархической кластеризации\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.scatterplot(data=data, x='hour', y='entry_diff', hue='agg_cluster', palette='viridis')\n",
    "# plt.title('Agglomerative Clustering')\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33e442349c257080"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Анализ кластеров K-Means\n",
    "kmeans_analysis = data.groupby('kmeans_cluster')[['hour', 'day_of_week', 'entry_diff', 'exit_diff']].mean()\n",
    "print(kmeans_analysis)\n",
    "\n",
    "# Анализ кластеров DBSCAN\n",
    "dbscan_analysis = data.groupby('dbscan_cluster')[['hour', 'day_of_week', 'entry_diff', 'exit_diff']].mean()\n",
    "print(dbscan_analysis)\n",
    "\n",
    "# Анализ кластеров иерархической кластеризации\n",
    "agg_analysis = data.groupby('agg_cluster')[['hour', 'day_of_week', 'entry_diff', 'exit_diff']].mean()\n",
    "print(agg_analysis)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76c028efe43cbb82"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_algorithm = 'K-Means' if kmeans_silhouette > max(dbscan_silhouette, agg_silhouette) else 'DBSCAN' if dbscan_silhouette > agg_silhouette else 'Agglomerative Clustering'\n",
    "\n",
    "print(f\"The best clustering algorithm is: {best_algorithm}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "314043024ac882aa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
